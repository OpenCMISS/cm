 /*!
\page installation Obtaining the Code and Setting up the Development Environment
\section before_start Before Start
Before the installation, you need to check if the following libraries or tools are installed, preferably to the latest or recent versions. 
They will be used during the installation process. 
- Intel Fortran Compiler (Optional: to compile the libraries and OpenCMISS with intel)
- subversion
- GNU make
- python
- python-dev
- python-setuptools
- bison
- yacc
- SWIG
- lesstif2-devel
- openmotif-devel
- libXmu-devel  
- libstdc++-devel
- csh

It would be great if you also have the following tools installed. 
However, if you don't have them installed or not have the right version, you can download and build them as part of the installation steps (See \ref step6 "Step 6"). 
To do this, you need to set the USE_OPENCMISS_xxx environment variables to true in \ref step4_2 "Step 4.2".
- cmake (you may install it later with libraries build)
- GNU Fortran (GCC) 4.4 or 4.6 or later (you may install it later with libraries build)
- git (you may install it later with libraries build)

\section opencmiss_installation Installations
To fully install OpenCMISS, you need to install OpenCMISSExtras and OpenCMISS. 
OpenCMISSExtras contains the third party libraries, compilers, tools, FieldML and CellML required for OpenCMISS. 
Please follow the steps for the complete installation of OpenCMISS on the linux systems.

\subsection step1 Step 1
Create OpenCMISSExtras directory and OpenCMISS directory
\code 
mkdir OpenCMISSExtras 
mkdir OpenCMISS 
\endcode

\subsection step2 Step 2
cd to the OpenCMISSExtras directory
\code cd OpenCMISSExtras \endcode 

\subsection step3 Step 3
In the OpenCMISSExtras directory, check out the utils repository: 
\code svn co https://svn.physiomeproject.org/svn/opencmissextras/utils/trunk/ utils \endcode

\subsection step4 Step 4
Set up your shell login script to call the opencmiss_programer script, which will set environment variables used when building OpenCMISS.

1. Set the environment variables OPENCMISS_ROOT and OPENCMISSEXTRAS_ROOT to point to the directories that are created in \ref step1 "Step 1".

If you use the bash shell you can do this by adding the following lines to your "~/.bashrc" file:
\code 
export OPENCMISS_ROOT=<path to your OpenCMISS folder>
export OPENCMISSEXTRAS_ROOT=<path to your OpenCMISSExtras folder>
\endcode
If you use C Shell or tcsh Shell you can do this by adding the following lines to your "~/.cshrc" or "~/.tcshrc" file:
\code 
setenv OPENCMISS_ROOT <path to your OpenCMISS folder> 
setenv OPENCMISSEXTRAS_ROOT <path to your OpenCMISSExtras folder> 
\endcode 

2. Set any additional programmer script variables. 
\anchor step4_2
The opencmiss_programmers script in $OPENCMISSEXTRAS_ROOT/utils/scripts will let you customise the setup by setting environment variables after the root sets and before executing the script. These variables are:
- COMPILER : set the compiler to be used as the default. Options are gnu and intel.
- USE_OPENCMISS_GFORTRAN : if set use the gfortran in the OpenCMISSextras repository. If not set use the system gfortran.
- USE_OPENCMISS_CMAKE : if set use the cmake in the OpenCMISSextras repository. If not set use the system cmake.
- USE_OPENCMISS_GIT : if set use the git in the OpenCMISSextras repository. If not set use the system git.
- GNU_COMPILER_VERSION : if using the OpenCMISSextras gfortran set what version to use. Options are 4.4, 4.5 or 4.6.
- OPENCMISSEXTRAS_RUN_CONFIG : select which configuration of the OpenCMISSextras binaries to use at runtime. Options are debug or optimised.
- MPI : select what version of MPI to use. Options are mpich2, intel, mvapich2 or openmpi.

The following variables are not required if you are using Intel compiler version 12 or above: 
- INTEL_COMPILER_VERSION : if using the pre 12.0 version of the intel compilers the compiler version to use e.g., 11.1
- INTEL_COMPILER_BUILD : if using the pre 12.0 version of the intel compilers the build version to use e.g., 072
- INTEL_TRACE_COLLECTOR_VERSION : the version of the intel trace collector to use e.g., 8.0.1.009
- INTEL_MPI_VERSION : the version of the intel MPI to use e.g., 4.0.1.007

3. Add in the lines in the login script to run the script:

If you use the bash shell you can do this by adding the following lines to your "~/.bashrc" file:
\code 
if [ -x ${OPENCMISSEXTRAS_ROOT}/utils/scripts/opencmiss_programmer.sh ]; then
  . ${OPENCMISSEXTRAS_ROOT}/utils/scripts/opencmiss_programmer.sh
fi
\endcode
If you use a c to tc shell you can do this by adding the following lines to your "/.cshrc" or "~/.tcshrc" file:
\code 
if ( -r ${OPENCMISSEXTRAS_ROOT}/utils/scripts/opencmiss_programmer.csh ) then
  source ${OPENCMISSEXTRAS_ROOT}/utils/scripts/opencmiss_programmer.csh 
endif
\endcode 

4.  Run the login script by either loging out and then back in or by sourcing it.
If you use the bash shell, you can execute:
\code . ~/.bashrc \endcode
If you use a c  shell, you can execute:
\code source ~/.cshrc \endcode
If you use tc shell, you can execute:
\code source ~/.tcshrc \endcode 

\subsection step5 Step 5
cd to the $OPENCMISSEXTRAS_ROOT/utils dir
\code cd $OPENCMISSEXTRAS_ROOT/utils \endcode

\subsection step6 Step 6
Now you are ready to build OpenCMISSExtras via the make script.

1. Checkout or update the required libraries from the repositories. 
If there is no previous checkout, you may use:
\code make checkout \endcode
If you have checked out or built the libraries before, use:
\code make update \endcode
If you want to build gfortran, cmake or git from the OpenCMISSExtras repository, 
you need to define the relevant USE_OPENCMISS_xxx environment variables described in \ref step4_2 "Step 4.2". 

2. Clean the builds (Optional).
If you want to clean the previous build and do a fresh build, you may use:
\code make clean \endcode
If the relevant USE_OPENCMISS_xxx environment variables are set, it will also clean the gfortran, cmake or git build from the OpenCMISSExtras repository. 

3. Build the OpenCMISSExtras libraries.
To build the OpenCMISSExtras libraries, use:
\code make \endcode
You may specify the following options to the build:
- ABI=(32|64): to build 32 bit or 64 bit libraries
- COMPILER=(intel|gnu|ibm|cray): to use the fortran and c compiler as specified
- (DEBUG=|OPT=): compiler the libraries to the debug version or optimised (release) version
- MPI=(mpich2|intel|openmpi|mvapich2|cray): to use the mpi as specified
- PROF=(true|): to do a profile build
- MPIPROF=(true|): to do a profile build with mpi

For example, to build the optimised version of libraries using the Intel compiler:
\code make COMPILER=intel OPT=true \endcode

\subsection step7 Step 7
cd to the OpenCMISS folder that is created in \ref step1 "Step 1".
\code cd $OPENCMISS_ROOT \endcode

\subsection step8 Step 8
To obtain the OpenCMISS source you need to clone the Git repository.
There are three parts of OpenCMISS to obtain - OpenCMISS itself, the OpenCMISS examples, and OpenCMISS CellML.

If you wish to make changes to OpenCMISS it is recommended that you fork the repositories on GitHub so that
your changes can be pulled into the central repository from your GitHub account.
The process of forking the OpenCMISS repositories and the workflow to use with Git is described in
a page on the OpenCMISS wiki (https://sourceforge.net/apps/mediawiki/opencmiss/index.php?title=Proposed_Workflow). 

The OpenCMISS cm repository is at https://github.com/OpenCMISS/cm.

The OpenCMISS examples repository is at https://github.com/OpenCMISS/examples/.

The OpenCMISS cellml repository is at https://github.com/OpenCMISS/cellml/.

Once you have forked the OpenCMISS cm, examples and cellml repositories on GitHub, you can clone them
to your local machine by issuing the following commands in the OpenCMISS directory,
where <username> should be replaced with your GitHub username:
\code git clone https://github.com/<username>/cm.git cm
 git clone https://github.com/<username>/examples.git examples
 git clone https://github.com/<username>/cellml.git cellml \endcode
If you know you will not need to make changes to one or more of the repositories you can
clone them directly from https://github.com/OpenCMISS/.

You can also clone example repository to a location other than $OPENCMISS_ROOT/examples directory. 
To do this, you need to specify the OPENCMISSEXAMPLES_ROOT variable in your login script:
\code
export OPENCMISSEXAMPLES_ROOT=<path to your examples folder>
\endcode
If you use C Shell or tcsh Shell you can do this by adding the following lines to your "~/.cshrc" or "~/.tcshrc" file:
\code
setenv OPENCMISSEXAMPLES_ROOT <path to your examples folder>
\endcode 

\subsection step9 Step 9
Build the OpenCMISS celllml.

1. cd to the cellml directory.
\code cd $OPENCMISS_ROOT/cellml \endcode

2. Build the OpenCMISS cellml
\code make \endcode
You may specify the following options to the build:
- ABI=(32|64): to build 32 bit or 64 bit libraries
- COMPILER=(intel|gnu|ibm|cray): to use the fortran and c compiler as specified
- (DEBUG=|OPT=): compiler the libraries to the debug version or optimised (release) version

\subsection step10 Step 10
Build OpenCMISS. 

1. cd to the cm directory.
\code cd $OPENCMISS_ROOT/cm \endcode

2. Build the OpenCMISS.
\code make \endcode
You may specify the following options to the build:
- (DEBUG=|OPT=): compiler the libraries to the debug version or optimised (release) version
- MPI=(mpich2|intel|openmpi|mvapich2|cray): to use the mpi as specified
- PROF=(true|): to do a profile build
- MPIPROF=(true|): to do a profile build with mpi
- ABI=(32|64): to build 32 bit or 64 bit libraries
- COMPILER=(intel|gnu|ibm|cray): to use the fortran and c compiler as specified
- USECELLML=(false|true): to use CellML or not
- USEFIELDML=(false|true): to use FieldML or not

For example, to build the optimised version of libraries using the Intel compiler and FieldML:
\code make COMPILER=intel OPT=true USEFIELDML=true \endcode

3. Build OpenCMISS with Python binding.
You may build OpenCMISS with python binding by
\code make python \endcode

\subsection step11 Step 11
Build an example.

1. cd to an example directory, e.g the Laplace example
\code cd $OPENCMISSEXAMPLES_ROOT/ClassicalField/Laplace/Laplace/Fortran \endcode

2. Build the example
\code make \endcode
You may specify the following options to the build:
- (DEBUG=|OPT=): compiler the libraries to the debug version or optimised (release) version
- MPI=(mpich2|intel|openmpi|mvapich2|cray): to use the mpi as specified
- PROF=(true|): to do a profile build
- MPIPROF=(true|): to do a profile build with mpi
- ABI=(32|64): to build 32 bit or 64 bit libraries
- COMPILER=(intel|gnu|ibm|cray): to use the fortran and c compiler as specified
- USECELLML=(false|true): to use CellML or not
- USEFIELDML=(false|true): to use FieldML or not

3. Execute the example:
You may specify the arguments to execute the example, e.g.
\code ./bin/x86_64-linux/mpich2/gnu_4.4/LaplaceExample-debug 4 4 4 1 \endcode

4. Execute the example with mpi:
To execute the example with mpi, you first need to start mpi.
\code mpd & \endcode
and then e.g. execute the examples running on two computational nodes:
\code mpiexec -2 ./bin/x86_64-linux/mpich2/gnu_4.4/LaplaceExample-debug 4 4 4 2 \endcode

5. Build and execute examples with python binding, e.g.
\code cd $OPENCMISSEXAMPLES_ROOT/ClassicalField/Laplace/Laplace/Python \endcode
and
\code python ./LaplaceExample.py \endcode

\section additional Additional Notes

If you are using totalview, after installation you will also need to add
\code export LM_LICENSE_FILES=<path-to-the-flex-directory> \endcode respectively, 
\code setenv LM_LICENSE_FILES <path-to-the-flex-directory> \endcode

Details of totalview installation can be found <a href="http://www.roguewave.com/documents.aspx?entryid=1142&command=core_download">here</a>.  

-For ABI users, you may use totalview installed in hpc3. It is installed in /usr/toolwork. Please make sure that you have set LM_LICENSE_FILES
\code export LM_LICENSE_FILES=/usr/toolworks/flexlm-10.8.0-3/ \endcode respectively, 
\code setenv LM_LICENSE_FILES /usr/toolworks/flexlm-10.8.0-3/ \endcode



\internal

\section obtain_code_and_libraries Obtaining the Code and Libraries

\subsubsection build_libraries Build the Libraries from scratch
You may checkout the libraries sources and build the libraries from scratch. It is highly recommended that you do in this way but it takes time. 

You need to have the following software tools or libraries installed apart from the standard install, preferably to the latest or recent versions:
- cmake (you may install it later with libraries build)
- GNU Fortran (GCC) 4.4 or 4.6 or later (you may install it later with libraries build)
- git (you may install it later with libraries build)
- Intel Fortran Compiler (Optional: to compile the libraries and OpenCMISS with intel)
- subversion
- GNU make
- python
- python-dev
- python-setuptools
- bison
- SWIG
- lesstif2-devel
- openmotif-devel
- libXmu-devel  
- libstdc++-devel

1. Create an opencmissextras directory and set the environment variable to point to that directory:
\code setenv OPENCMISSEXTRAS_ROOT <path to your opencmissextras folder>\endcode or \code export OPENCMISSEXTRAS_ROOT=<path to your opencmissextras folder>\endcode

2. Checkout the utils component in opencmissextras from the repository to the opencmissextras directory. 
\code svn co https://svn.physiomeproject.org/svn/opencmissextras/utils/trunk/ utils \endcode

3. Checkout all the required libraries to the opencmissextras directory.
\code make checkout \endcode by default, it will checkout the following components:
- mpi
- common
- cellml
- fieldml
- cm
.
However, if you don't have cmake, gfortran or git installed, you may checkout their sources by specifying:
\code make checkout USE_OPENCMISS_GFORTRAN=true 
 make checkout USE_OPENCMISS_CMAKE=true 
 make checkout USE_OPENCMISS_GIT=true \endcode
or any combination of those.

4. (Optional) Clean the build. In the utils directory, execute:
\code make clean \endcode
this is only for those who have built the libraries in the directory before and want to do a clean build.

5. Build the libraries. In the utils directory, execute:
\code make COMPILER=intel \endcode to build the libraries using Intel Fortran Compiler or
\code make COMPILER=gnu \endcode to build the libraries using GNU Fortran Compiler.
By default, it will build the following components:
- mpi
- common
- cellml
- fieldml
- cm
.
However, if you have checked out cmake, gfortran or git and want to build and use it within opencmiss, you can build those libraries by specifying:
\code make USE_OPENCMISS_GFORTRAN=true 
 make USE_OPENCMISS_CMAKE=true 
 make USE_OPENCMISS_GIT=true \endcode
or any combination of those. Please also make sure you use the correct compiler.

\subsubsection download_libraries Download the prebuilt binaries

Alternatively, you can checkout the prebuilt binaries of the various components from the svn repository. However, it is not guaranteed that the binaries work for the operating system you are using.

To check out the main trunk of the various cm libraries required with OpenCMISS issue the following command in the opencmissextras directory:
\code svn co https://svn.physiomeproject.org/svn/opencmissextras/cm/trunk/external/architecture cm/external/architecture \endcode
where architecture is the appropriate architecture for the machine. Possible architectures are:
- i386-win32
- i386-win32-debug
- i686-linux
- i686-linux-debug
- ppc-64-linux
- ppc-64-linux-debug
- rs6000-32-aix
- rs6000-32-aix-debug
- x86_64-linux
- x86_64-linux-debug
- x86_64-linux-mpiprof
- x86_64-linux-prof

To check out the main trunk of the various MPI libraries required with OpenCMISS issue the following command in the opencmissextras directory:
\code svn co https://svn.physiomeproject.org/svn/opencmissextras/mpi/trunk/architecture mpi/architecture \endcode
where architecture is the appropriate architecture for the machine. Currently, the list of possible achitectures comprehends:
- none

To check out the main trunk of the various cellml libraries required with OpenCMISS issue the following command in the opencmissextras directory:
\code svn co https://svn.physiomeproject.org/svn/opencmissextras/cellml/trunk/architecture cellml/architecture \endcode
where architecture is the appropriate architecture for the machine. Currently, the list of possible achitectures comprehends:
- i386-win32-debug
- x86_64-linux
- x86_64-linux-debug

To check out the main trunk of the various fieldml libraries required with OpenCMISS issue the following command in the opencmissextras directory:
\code svn co https://svn.physiomeproject.org/svn/opencmissextras/fieldml/trunk/architecture fieldml/architecture \endcode
where architecture is the appropriate architecture for the machine. Currently, the list of possible achitectures comprehends:
- i686-linux
- i686-linux-debug
- x86_64-linux
- x86_64-linux-debug

To check out the main trunk of the various common libraries required with OpenCMISS issue the following command in the opencmissextras directory:
\code svn co https://svn.physiomeproject.org/svn/opencmissextras/common/trunk/architecture common/architecture \endcode
where architecture is the appropriate architecture for the machine. Currently, the list of possible achitectures comprehends:
- i686-linux
- i686-linux-debug
- x86_64-linux
- x86_64-linux-debug


Finally, to check out the main trunk of the various utils in the code repository. To check it out issue the following command in the opencmissextras directory:
\code svn co https://svn.physiomeproject.org/svn/opencmissextras/utils/trunk utils\endcode

-For Auckland users, you may simply set your OPENCMISSEXTRAS_ROOT environment variable to point to the libraries on hpc without creating an opencmissextras directory:
\code setenv OPENCMISSEXTRAS_ROOT /hpc/cmiss/opencmissextras\endcode or \code export OPENCMISSEXTRAS_ROOT=/hpc/cmiss/opencmissextras\endcode

\section project_setup Project Setup

\subsection project_setup_aix On AIX 5.3 (HPC)

\subsubsection project_setup_hpc_environment Set environment

Set environment variable to point to OpenCMISS
\code setenv OPENCMISS_ROOT <path to your opencmiss folder>\endcode or \code export OPENCMISS_ROOT=<path to your opencmiss folder>\endcode
Set environment variable to point to OpenCMISS-extras
\code setenv OPENCMISSEXTRAS_ROOT <path to your opencmissextras folder>\endcode or \code export OPENCMISSEXTRAS_ROOT=<path to your opencmissextras folder>\endcode
Set environment variable to point to OpenCMISS examples
\code setenv OPENCMISSEXAMPLES_ROOT <path to your opencmiss folder>/examples\endcode or \code export OPENCMISSEXAMPLES_ROOT=<path to your opencmiss folder>/examples\endcode
\subsubsection project_setup_hpc_mpi Set MPI
Create a file called hostfile.list in your home directory.
Inside the file, add several lines of "hpc.bioeng.auckland.ac.nz"
In .rhost file in the home directory, add "hpc <username>" 
\subsubsection project_setup_aix_compile Compile
Change directory to opencmiss/cm
Change directory to examples/<example>
Use gmake.
This should result in a binary that you can run in the bin/rs6000-32-aix folder.

\subsection project_setup_linux On Ubuntu 12.04

\subsubsection project_setup_linux_compiler Install Compilers

\subsubsection project_setup_linux_environment Set environment

You need to set the environment variable to point to opencmiss and opencmissextras and execute the opencmiss_programmers script. 

If you use the bash shell you can do this by adding the following lines to your "~/.bashrc" file:
\code 
export OPENCMISS_ROOT=<path to your opencmiss folder>
export OPENCMISSEXTRAS_ROOT=<path to your opencmissextras folder>
export OPENCMISSEXAMPLES_ROOT=<path to your opencmiss folder>/examples
if [ -x ${OPENCMISSEXTRAS_ROOT}/utils/scripts/opencmiss_programmer.sh ]; then
  . ${OPENCMISSEXTRAS_ROOT}/utils/scripts/opencmiss_programmer.sh
fi
\endcode
If you use a c to tc shell you can do this by adding the following lines to your "/.cshrc" or "~/.tcshrc" file:
\code 
setenv OPENCMISS_ROOT <path to your opencmiss folder> 
setenv OPENCMISSEXTRAS_ROOT <path to your opencmissextras folder> 
setenv OPENCMISSEXAMPLES_ROOT <path to your opencmiss folder>/examples
if ( -r ${OPENCMISSEXTRAS_ROOT}/utils/scripts/opencmiss_programmer.csh ) then
  source ${OPENCMISSEXTRAS_ROOT}/utils/scripts/opencmiss_programmer.csh 
endif
\endcode 

The opencmiss_programmers script will let you customise the setup by setting environment variables after the root sets and before executing the script. These variables are:
- COMPILER : set the compiler to be used as the default. Options are gnu and intel.
- USE_OPENCMISS_GFORTRAN : if set use the gfortran in the OpenCMISSextras repository. If not set use the system gfortran.
- GNU_COMPILER_VERSION : if using the OpenCMISSextras gfortran set what version to use. Options are 4.4 and 4.5.
- OPENCMISSEXTRAS_RUN_CONFIG : select which configuration of the OpenCMISSextras binaries to use at runtime. Options are debug or optimised.
- MPI : select what version of MPI to use. Options are mpich2, intel or openmpi.
- INTEL_COMPILER_VERSION : if using the pre 12.0 version of the intel compilers the compiler version to use e.g., 11.1
- INTEL_COMPILER_BUILD : if using the pre 12.0 version of the intel compilers the build version to use e.g., 072
- INTEL_TRACE_COLLECTOR_VERSION : the version of the intel trace collector to use e.g., 8.0.1.009
- INTEL_MPI_VERSION : the version of the intel MPI to use e.g., 4.0.1.007

If you are using totalview, after installation you will also need to add
\code export LM_LICENSE_FILES=<path-to-the-flex-directory> \endcode respectively, 
\code setenv LM_LICENSE_FILES <path-to-the-flex-directory> \endcode

Details of totalview installation can be found <a href="http://www.roguewave.com/documents.aspx?entryid=1142&command=core_download">here</a>.  

-For ABI users, you may use totalview installed in hpc3. It is installed in /usr/toolwork. Please make sure that you have set LM_LICENSE_FILES
\code export LM_LICENSE_FILES=/usr/toolworks/flexlm-10.8.0-3/ \endcode respectively, 
\code setenv LM_LICENSE_FILES /usr/toolworks/flexlm-10.8.0-3/ \endcode

\subsubsection project_setup_linux_compile Compile

To build the OpenCMISS library issue the following command into the ".../<OPENCMISS_ROOT>/cm" directory:
\code make \endcode

Note, the default is the intel compiler. To explicitly use the gnu compiler use
\code make COMPILER=gnu \endcode
or set the COMPILER environment variable to be gnu.

To build an example project issue the following command into the ".../<OPENCMISSEXAMPLES_ROOT>/<example>/<sub-example>" directory:
\code make \endcode

Note, the default is the intel compiler. To explicitly use the gnu compiler use
\code make COMPILER=gnu \endcode
or set the COMPILER environment variable to be gnu.

To run the example project issue the following command into the directory where the executable is found (e.g. ".../opencmiss/examples/ClassicalField/NewLaplace/bin/x86_64-linux/mpich2/intel", depending on your example, sub-example, architecture, MPI library, and compiler):
\code mpd & mpirun -n 2 ./<executable> \endcode
to run the executable on two processors. To debug the project using TotalView:
\code mpd & mpirun -tv 2 ./<executable> \endcode


section project_setup_windows_vs2005 On Windows XP (Visual Studio 2005)
\subsubsection project_setup_windows_vs2005_compiler Install Compilers
Download Intel Fortran Compiler.
Execute the exe file and follow the installation wizard.
\subsubsection project_setup_windows_vs2005_mpi Install MPI
Download MPICH2 from here.
You can either download the source archive and follow the README.windows file to install or download the installer to install.
Set bin folder to the path
To start the MPI, run \code smpd -start \endcode in command window.
NOTE: as from MPICH2 version 1.0.7 the library names have changed. libmpich2 has now become libmpi!
\subsubsection project_setup_windows_vs2005_compile Compile and Debug
Build the Fortran project under the debug mode and generate the opencmisstest-debug.exe file.
In the C Project (since the Fortran projects do not support MPI cluster debugger), configure the debugging properties according to this.
The MPIShim location is in the path similar to C:\Program Files\Microsoft Visual Studio 8\Common7\IDE\Remote Debugger\x86\mpishim.exe.
Debug the C project.
\subsubsection project_setup_windows_vs2005_run Run
To run the project in the command window:
\code mpiexec -n 2 -localroot <path to the execution file> \endcode

\subsection project_setup_windows_vs2008 On Windows Vista (Visual Studio 2008)
\subsubsection project_setup_windows_vs2008_compiler Install Compilers
Download Intel Fortran Compiler from here.
Execute the exe file and follow the installation wizard.
\subsubsection project_setup_windows_vs2008_mpi Install MPI
Before you install MPICH2 under Vista you must turn off User Account Control
-# Goto Start -> Control Panel
-# Double-click on User Accounts
-# Click "Turn User Account Control on or off"
-# Untick "Use User Account Control (UAC) to help protect your computer" and click OK
-# Restart your computer.
.
Download from here. Choose the Win32 IA32 (binary) option.
Run the downloaded .msi file. Follow all instructions and install "For everybody".
Once you have installed MPICH2 you can turn User Account Control back on. Follow the instructions above and in 4. tick the "Use User Account Control ...".
NOTE: as from MPICH2 version 1.0.7 the library names have changed. libmpich2 has now become libmpi!
\subsubsection project_setup_windows_vs2008_compile Compile
For each example, go into the VisualOpenCMISS_08 folder. Double click the VisualOpenCMISS project solution file to lauch Visual Studio.

\section libraries_build Libraries Build (Optional)
\subsection libraries_build_petsc Compiling PETSc
Note this is assuming you have the Intel Fortran compiler version 10.1.024. Adjust the version string as necessary.
\subsubsection libraries_build_petsc_step1 Step1: Linux Environment installation and Compiler Environment Set up (For Windows only)
Under windows system:
- Install Cygwin if you need to. Cywin can be found here. Make sure you include the make and python modules when you install.
- Launch a Command Prompt Window
- Run the ifortvars.bat batch file to setup your Intel Fortran environment. e.g., "C:\Program Files\Intel\Compiler\Fortran\10.1.024\IA32\Bin\ifortvars.bat"
- Run the Cygwin batch file to setup the unix environment e.g., "C:\Cygwin\Cygwin.bat"
.
N.B: PetSc uses X, so make sure in linux environment, libX11-dev package is installed.
Also make sure blas and lapack (-dev) packages are installed. 
\subsubsection libraries_build_petsc_step2 Step2: Compile PETSC
\paragraph libraries_build_petsc_step2_windows For Windows
- Change to the opencmissextras PETSc directory e.g., if opencmissextras root is E:\opencmissextras and we are compiling PETSC version petsc-2.3.3-p8 then "cd /cygwin/e/opencmissextras/cm/external/packages/PETSc/petsc-2.3.3-p8"
- If you have MPICH2 version 1.0.7 or greater edit the python/BuildSystem/config/packages/MPI.py file. Find the self.liblist_mpich line. After the line "['fmpich2.lib','mpich2.lib']," add the line "['fmpich2.lib','mpi.lib'],".
- \code PETSC_DIR=/cygdrive/e/opencmissextras/cm/external/packages/PETSc/petsc-2.3.3-p8; export PETSC_DIR \endcode
- For a debug install issue the following commands
\code PETSC_ARCH=cygwin-c-debug; export PETSC_ARCH 
config/configure.py --prefix=/cygdrive/e/opencmissextras/cm/external/i386-win32-debug --with-shared=no --with-cc='win32fe cl' --with-fc='win32fe ifort' --with-cxx='win32fe cl' --download-f-blas-lapack=1 LIBS=-L'/cygdrive/c/Program\ Files/Intel/Compiler/Fortran/10.1.024/IA32/Lib' --with-debugging=yes
PETSC_ARCH=cygwin-c-debug; export PETSC_ARCH \endcode
For a non-debug install issue the following commands
\code PETSC_ARCH=cygwin-c-opt; export PETSC_ARCH
config/configure.py --prefix=/cygdrive/e/opencmissextras/cm/external/i386-win32 --with-shared=no --with-cc='win32fe cl' --with-fc='win32fe ifort' --with-cxx='win32fe cl' --download-f-blas-lapack=1 LIBS=-L'/cygdrive/c/Program\ Files/Intel/Compiler/Fortran/10.1.024/IA32/Lib' --with-debugging=no
PETSC_ARCH=cygwin-c-opt; export PETSC_ARCH \endcode
- \code make -e all \endcode
- \code make -e install \endcode
\paragraph libraries_build_petsc_step2_aix For AIX5.3
- Change to the opencmissextras PETSc directory. e.g /people/tyu011/workspace/opencmissextras/cm/external/packages/PETSc/petsc-2.3.3-p8
- setenv PETSC_DIR /people/tyu011/workspace/opencmissextras/cm/external/packages/PETSc/petsc-2.3.3-p8
- In config directory, copy the file aix5.1.0.0.py and rename it to aix5.3.0.0.py
- For a debug install issue the following commands
\code setenv PETSC_ARCH aix5.3.0.0
config/aix5.3.0.0.py --prefix=/people/tyu011/workspace/opencmissextras/cm/external/rs6000-32-aix-debug --with-debugging=yes
setenv PETSC_ARCH aix5.3.0.0 \endcode
For a non-debug install issue the following commands
\code setenv PETSC_ARCH aix5.3.0.0
config/aix5.3.0.0.py --prefix=/people/tyu011/workspace/opencmissextras/cm/external/rs6000-32-aix --with-debugging=no
setenv PETSC_ARCH aix5.3.0.0 \endcode
- \code make -e all \endcode
- \code make -e install \endcode
\endinternal
*/

\section makefile_structure Makefile Structure
The top level makefile (located in "<path to your root OpenCMISS directory>/opencmiss/cm/") will build the OpenCMISS library. Issue the following commands in the ".../opencmiss/cm/" directory:
\code make \endcode or, if you want to use the GNU compiler (Version 4.4 or greater) \code make COMPILER=gnu \endcode
In the examples directory there are separate compilable "applications" with individual makefiles, e.g. in ".../opencmiss/examples/ClassicalField/NewLaplace". How to compile the examples will be explained further below.

\section programmer_documentation Programmer documentation
This programmer documentation is written using doxygen with the source located in the ".../opencmiss/cm/doc/doxygen/additional_doc/" folder. The source XML code can be transformed into documents in HTML format. Issue the following command into the ".../opencmiss/cm/doc/doxygen/" directory:
\code doxygen Doxyfile \endcode
It will build a number of html pages in the ".../opencmiss/cm/doc/doxygen/Programmer/html" directory, which can be read by opening the "index.html" file in a web browser. 

